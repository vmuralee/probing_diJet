{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ROOT\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from Data2Array import Data2Array,Array2Data\n",
    "import argparse\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['ptJ1','ptJ2','invmass','DRJ1J2','etaJ1','etaJ2']\n",
    "#labels = labels+['pTDJ1','pTDJ2','LHAJ1','LHAJ2','e05J1','e05J2','s2J1','s2J2','pmJ1','pmJ2','tmJ1','tmJ2','widthJ1','widthJ2','girthJ1','girthJ2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames =['pp2jj_SMbkg-Nev2e6-ptJetMin700-antiktR0.4-zcut0.1-beta1.0.root','pp2coloron2_qq-Nev2e6-ptJetMin700-antiktR0.4-zcut0.1-beta1.0.root']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../data/Ntuples/pp2jj_SMbkg-Nev2e6-ptJetMin700-antiktR0.4-zcut0.1-beta1.0.root\n",
      "loading data from ../data/Ntuples/pp2coloron2_qq-Nev2e6-ptJetMin700-antiktR0.4-zcut0.1-beta1.0.root\n"
     ]
    }
   ],
   "source": [
    "data = Data2Array('../data/Ntuples',filenames,labels,(0,10000))\n",
    "data_ar = data.load_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Training,Test and Validation samples\n",
    "traindataset_full,testdataset = train_test_split(data_ar,test_size=0.1,random_state=42)\n",
    "traindataset,valdataset = train_test_split(traindataset_full,test_size=0.2,random_state=42)\n",
    "trainData = copy.deepcopy(traindataset)\n",
    "valData = copy.deepcopy(valdataset)\n",
    "\n",
    "\n",
    "X_train,X_val = trainData.drop('target',axis=1).to_numpy(dtype='float64'),valData.drop('target',axis=1).to_numpy(dtype='float64')\n",
    "y_train,y_val = trainData['target'].to_numpy(dtype='float64'),valData['target'].to_numpy(dtype='float64')\n",
    "X_test,y_test = testdataset.drop('target',axis=1).to_numpy(dtype='float64'),testdataset['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label dims:  (1191381, 6)    Output dims:  (1191381, 2)\n"
     ]
    }
   ],
   "source": [
    "#TransForming Data\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler',StandardScaler()),\n",
    "])\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "X_train_tr,X_val_tr = num_pipeline.fit_transform(X_train),num_pipeline.fit_transform(X_val)\n",
    "y_train_tr,y_val_tr = encoder.fit_transform(trainData[['target']]).toarray(),encoder.fit_transform(valData[['target']]).toarray()\n",
    "X_test_ = num_pipeline.fit_transform(X_test)\n",
    "y_test_ = encoder.fit_transform(testdataset[['target']]).toarray()\n",
    "print('Label dims: ',X_train_tr.shape,'   Output dims: ',y_train_tr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning DNN model\n",
    "\n",
    "def build_model(n_hidden=1,n_neurons=30,learning_rate=3e-3,input_shapes=[6]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shapes))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons,activation='relu'))\n",
    "    model.add(keras.layers.Dense(2,activation='sigmoid'))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\",optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37231/37231 [==============================] - 78s 2ms/step - loss: 0.1858 - val_loss: 0.1643\n",
      "Epoch 2/10\n",
      "37231/37231 [==============================] - 78s 2ms/step - loss: 0.1600 - val_loss: 0.1559\n",
      "Epoch 3/10\n",
      "37231/37231 [==============================] - 79s 2ms/step - loss: 0.1554 - val_loss: 0.1532\n",
      "Epoch 4/10\n",
      "37231/37231 [==============================] - 79s 2ms/step - loss: 0.1533 - val_loss: 0.1515\n",
      "Epoch 5/10\n",
      "37231/37231 [==============================] - 80s 2ms/step - loss: 0.1518 - val_loss: 0.1501\n",
      "Epoch 6/10\n",
      "37231/37231 [==============================] - 77s 2ms/step - loss: 0.1505 - val_loss: 0.1489\n",
      "Epoch 7/10\n",
      "37231/37231 [==============================] - 76s 2ms/step - loss: 0.1494 - val_loss: 0.1479\n",
      "Epoch 8/10\n",
      "37231/37231 [==============================] - 76s 2ms/step - loss: 0.1486 - val_loss: 0.1471\n",
      "Epoch 9/10\n",
      "37231/37231 [==============================] - 77s 2ms/step - loss: 0.1479 - val_loss: 0.1465\n",
      "Epoch 10/10\n",
      "37231/37231 [==============================] - 78s 2ms/step - loss: 0.1473 - val_loss: 0.1459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa1681f8d60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train_tr,y_train,epochs=10,validation_data=(X_val_tr,y_val),callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5171/5171 [==============================] - 9s 2ms/step - loss: 0.3494\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test_,y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[1,2,3,4],\n",
    "    'n_neurons':np.arange(1,500),\n",
    "    'learning_rate':reciprocal(3e-4,3e-2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv=RandomizedSearchCV(keras_reg,param_distribs,n_iter=10,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.2101 - val_loss: 0.1913\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 59s 2ms/step - loss: 0.1840 - val_loss: 0.1767\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1726 - val_loss: 0.1677\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1654 - val_loss: 0.1621\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1611 - val_loss: 0.1587\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1584 - val_loss: 0.1565\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1566 - val_loss: 0.1550\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 58s 2ms/step - loss: 0.1554 - val_loss: 0.1540\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1544 - val_loss: 0.1531\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1537 - val_loss: 0.1525\n",
      "12411/12411 [==============================] - 20s 2ms/step - loss: 0.1536\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.2080 - val_loss: 0.1883\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1811 - val_loss: 0.1738\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1700 - val_loss: 0.1655\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1637 - val_loss: 0.1607\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1601 - val_loss: 0.1579\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1579 - val_loss: 0.1561\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1565 - val_loss: 0.1549\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1554 - val_loss: 0.1539\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1546 - val_loss: 0.1532\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1539 - val_loss: 0.1525\n",
      "12411/12411 [==============================] - 20s 2ms/step - loss: 0.1533\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.2064 - val_loss: 0.1887\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1816 - val_loss: 0.1748\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1711 - val_loss: 0.1667\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 59s 2ms/step - loss: 0.1650 - val_loss: 0.1620\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1613 - val_loss: 0.1591\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1590 - val_loss: 0.1571\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1574 - val_loss: 0.1558\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1562 - val_loss: 0.1547\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1553 - val_loss: 0.1539\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1546 - val_loss: 0.1532\n",
      "12411/12411 [==============================] - 20s 2ms/step - loss: 0.1543\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.2035 - val_loss: 0.1808\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 76s 3ms/step - loss: 0.1706 - val_loss: 0.1611\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 76s 3ms/step - loss: 0.1576 - val_loss: 0.1539\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 76s 3ms/step - loss: 0.1534 - val_loss: 0.1514\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1516 - val_loss: 0.1499\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1503 - val_loss: 0.1487\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1493 - val_loss: 0.1478\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 76s 3ms/step - loss: 0.1484 - val_loss: 0.1470\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 76s 3ms/step - loss: 0.1477 - val_loss: 0.1463\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 76s 3ms/step - loss: 0.1471 - val_loss: 0.1457\n",
      "12411/12411 [==============================] - 22s 2ms/step - loss: 0.1470\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 76s 3ms/step - loss: 0.2089 - val_loss: 0.1827\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1722 - val_loss: 0.1627\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 76s 3ms/step - loss: 0.1591 - val_loss: 0.1549\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 76s 3ms/step - loss: 0.1543 - val_loss: 0.1520\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1522 - val_loss: 0.1503\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1507 - val_loss: 0.1490\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1496 - val_loss: 0.1480\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1487 - val_loss: 0.1472\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1480 - val_loss: 0.1465\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1474 - val_loss: 0.1460\n",
      "12411/12411 [==============================] - 22s 2ms/step - loss: 0.1470\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 76s 3ms/step - loss: 0.2096 - val_loss: 0.1802\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1677 - val_loss: 0.1585\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1561 - val_loss: 0.1529\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1526 - val_loss: 0.1505\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 57s 2ms/step - loss: 0.1507 - val_loss: 0.1490\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 38s 2ms/step - loss: 0.1495 - val_loss: 0.1479\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 43s 2ms/step - loss: 0.1486 - val_loss: 0.1470\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 38s 2ms/step - loss: 0.1478 - val_loss: 0.1464\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 44s 2ms/step - loss: 0.1472 - val_loss: 0.1458\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 39s 2ms/step - loss: 0.1467 - val_loss: 0.1454\n",
      "12411/12411 [==============================] - 13s 1ms/step - loss: 0.1464\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 37s 1ms/step - loss: 0.2252 - val_loss: 0.2102\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 31s 1ms/step - loss: 0.2033 - val_loss: 0.1974\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.1940 - val_loss: 0.1903\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.1881 - val_loss: 0.1852\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 31s 1ms/step - loss: 0.1837 - val_loss: 0.1812\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.1800 - val_loss: 0.1777\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.1768 - val_loss: 0.1747\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 32s 1ms/step - loss: 0.1741 - val_loss: 0.1721\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 37s 1ms/step - loss: 0.1716 - val_loss: 0.1698\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 34s 1ms/step - loss: 0.1695 - val_loss: 0.1678\n",
      "12411/12411 [==============================] - 10s 802us/step - loss: 0.1687\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.2306 - val_loss: 0.2141\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 37s 1ms/step - loss: 0.2067 - val_loss: 0.2002\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 33s 1ms/step - loss: 0.1965 - val_loss: 0.1923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.1899 - val_loss: 0.1866\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.1849 - val_loss: 0.1820\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 33s 1ms/step - loss: 0.1808 - val_loss: 0.1782\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.1773 - val_loss: 0.1749\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.1743 - val_loss: 0.1721\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 33s 1ms/step - loss: 0.1717 - val_loss: 0.1697\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 37s 1ms/step - loss: 0.1695 - val_loss: 0.1677\n",
      "12411/12411 [==============================] - 12s 976us/step - loss: 0.1683\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.2267 - val_loss: 0.2117\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.2047 - val_loss: 0.1988\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 37s 1ms/step - loss: 0.1951 - val_loss: 0.1913\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.1888 - val_loss: 0.1857\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.1839 - val_loss: 0.1813\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.1799 - val_loss: 0.1774\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 38s 2ms/step - loss: 0.1764 - val_loss: 0.1742\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.1734 - val_loss: 0.1714\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 37s 1ms/step - loss: 0.1708 - val_loss: 0.1690\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.1686 - val_loss: 0.1669\n",
      "12411/12411 [==============================] - 12s 970us/step - loss: 0.1677\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 58s 2ms/step - loss: 0.1535 - val_loss: 0.1446\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1448 - val_loss: 0.1432\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1441 - val_loss: 0.1430\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 57s 2ms/step - loss: 0.1439 - val_loss: 0.1430\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 57s 2ms/step - loss: 0.1438 - val_loss: 0.1430\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1437 - val_loss: 0.1428\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 54s 2ms/step - loss: 0.1437 - val_loss: 0.1428\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 57s 2ms/step - loss: 0.1436 - val_loss: 0.1428\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 57s 2ms/step - loss: 0.1436 - val_loss: 0.1428\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1435 - val_loss: 0.1431\n",
      "12411/12411 [==============================] - 16s 1ms/step - loss: 0.1441\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 58s 2ms/step - loss: 0.1542 - val_loss: 0.1448\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1450 - val_loss: 0.1435\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 57s 2ms/step - loss: 0.1443 - val_loss: 0.1430\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1441 - val_loss: 0.1429\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 56s 2ms/step - loss: 0.1440 - val_loss: 0.1428\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1439 - val_loss: 0.1427\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1439 - val_loss: 0.1427\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 56s 2ms/step - loss: 0.1438 - val_loss: 0.1430\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1438 - val_loss: 0.1429\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1437 - val_loss: 0.1427\n",
      "12411/12411 [==============================] - 15s 1ms/step - loss: 0.1436\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 53s 2ms/step - loss: 0.1541 - val_loss: 0.1449\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 54s 2ms/step - loss: 0.1451 - val_loss: 0.1434\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 52s 2ms/step - loss: 0.1443 - val_loss: 0.1430\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 54s 2ms/step - loss: 0.1441 - val_loss: 0.1429\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 52s 2ms/step - loss: 0.1439 - val_loss: 0.1428\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1439 - val_loss: 0.1428\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 54s 2ms/step - loss: 0.1438 - val_loss: 0.1432\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 54s 2ms/step - loss: 0.1438 - val_loss: 0.1430\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 53s 2ms/step - loss: 0.1437 - val_loss: 0.1427\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 54s 2ms/step - loss: 0.1437 - val_loss: 0.1431\n",
      "12411/12411 [==============================] - 14s 1ms/step - loss: 0.1439\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 63s 3ms/step - loss: 0.1819 - val_loss: 0.1586\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 64s 3ms/step - loss: 0.1553 - val_loss: 0.1518\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 63s 3ms/step - loss: 0.1514 - val_loss: 0.1492\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 63s 3ms/step - loss: 0.1493 - val_loss: 0.1475\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 63s 3ms/step - loss: 0.1478 - val_loss: 0.1462\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 63s 3ms/step - loss: 0.1468 - val_loss: 0.1454\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 64s 3ms/step - loss: 0.1461 - val_loss: 0.1448\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 63s 3ms/step - loss: 0.1456 - val_loss: 0.1444\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 63s 3ms/step - loss: 0.1452 - val_loss: 0.1441\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 63s 3ms/step - loss: 0.1449 - val_loss: 0.1438\n",
      "12411/12411 [==============================] - 16s 1ms/step - loss: 0.1451\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 64s 3ms/step - loss: 0.1825 - val_loss: 0.1592\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 64s 3ms/step - loss: 0.1556 - val_loss: 0.1519\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 76s 3ms/step - loss: 0.1516 - val_loss: 0.1492\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1494 - val_loss: 0.1474\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 79s 3ms/step - loss: 0.1469 - val_loss: 0.1453\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 81s 3ms/step - loss: 0.1462 - val_loss: 0.1447\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 75s 3ms/step - loss: 0.1457 - val_loss: 0.1442\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 72s 3ms/step - loss: 0.1453 - val_loss: 0.1439\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 69s 3ms/step - loss: 0.1450 - val_loss: 0.1437\n",
      "12411/12411 [==============================] - 17s 1ms/step - loss: 0.1446\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 66s 3ms/step - loss: 0.1825 - val_loss: 0.1594\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 63s 3ms/step - loss: 0.1557 - val_loss: 0.1519\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 66s 3ms/step - loss: 0.1515 - val_loss: 0.1492\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 63s 3ms/step - loss: 0.1493 - val_loss: 0.1474\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 59s 2ms/step - loss: 0.1479 - val_loss: 0.1462\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 56s 2ms/step - loss: 0.1469 - val_loss: 0.1453\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 57s 2ms/step - loss: 0.1462 - val_loss: 0.1447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 59s 2ms/step - loss: 0.1456 - val_loss: 0.1443\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 57s 2ms/step - loss: 0.1452 - val_loss: 0.1440\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 56s 2ms/step - loss: 0.1450 - val_loss: 0.1437\n",
      "12411/12411 [==============================] - 15s 1ms/step - loss: 0.1447\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 52s 2ms/step - loss: 0.2228 - val_loss: 0.1970\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 52s 2ms/step - loss: 0.1808 - val_loss: 0.1680\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 48s 2ms/step - loss: 0.1624 - val_loss: 0.1573\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 52s 2ms/step - loss: 0.1560 - val_loss: 0.1535\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 50s 2ms/step - loss: 0.1533 - val_loss: 0.1514\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 49s 2ms/step - loss: 0.1517 - val_loss: 0.1500\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 53s 2ms/step - loss: 0.1504 - val_loss: 0.1489\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 47s 2ms/step - loss: 0.1494 - val_loss: 0.1479\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 53s 2ms/step - loss: 0.1485 - val_loss: 0.1472\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 51s 2ms/step - loss: 0.1479 - val_loss: 0.1465\n",
      "12411/12411 [==============================] - 15s 1ms/step - loss: 0.1479\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 46s 2ms/step - loss: 0.2283 - val_loss: 0.2052\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 52s 2ms/step - loss: 0.1872 - val_loss: 0.1728\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 50s 2ms/step - loss: 0.1656 - val_loss: 0.1591\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 56s 2ms/step - loss: 0.1573 - val_loss: 0.1544\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 54s 2ms/step - loss: 0.1543 - val_loss: 0.1523\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 48s 2ms/step - loss: 0.1526 - val_loss: 0.1508\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 56s 2ms/step - loss: 0.1513 - val_loss: 0.1496\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 53s 2ms/step - loss: 0.1502 - val_loss: 0.1485\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 52s 2ms/step - loss: 0.1493 - val_loss: 0.1477\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 57s 2ms/step - loss: 0.1485 - val_loss: 0.1469\n",
      "12411/12411 [==============================] - 15s 1ms/step - loss: 0.1479\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 52s 2ms/step - loss: 0.2247 - val_loss: 0.2014\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1860 - val_loss: 0.1732\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1652 - val_loss: 0.1579\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 52s 2ms/step - loss: 0.1558 - val_loss: 0.1528\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 60s 2ms/step - loss: 0.1527 - val_loss: 0.1507\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 56s 2ms/step - loss: 0.1512 - val_loss: 0.1494\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 56s 2ms/step - loss: 0.1501 - val_loss: 0.1485\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 58s 2ms/step - loss: 0.1492 - val_loss: 0.1477\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 56s 2ms/step - loss: 0.1485 - val_loss: 0.1470\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 54s 2ms/step - loss: 0.1479 - val_loss: 0.1465\n",
      "12411/12411 [==============================] - 17s 1ms/step - loss: 0.1475\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 38s 2ms/step - loss: 0.1977 - val_loss: 0.1774\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 38s 2ms/step - loss: 0.1702 - val_loss: 0.1637\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 38s 2ms/step - loss: 0.1615 - val_loss: 0.1583\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.1577 - val_loss: 0.1557\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 49s 2ms/step - loss: 0.1558 - val_loss: 0.1541\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 45s 2ms/step - loss: 0.1545 - val_loss: 0.1530\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 44s 2ms/step - loss: 0.1535 - val_loss: 0.1522\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 37s 2ms/step - loss: 0.1527 - val_loss: 0.1514\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 40s 2ms/step - loss: 0.1520 - val_loss: 0.1507\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.1514 - val_loss: 0.1501\n",
      "12411/12411 [==============================] - 12s 964us/step - loss: 0.1513\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 41s 2ms/step - loss: 0.1955 - val_loss: 0.1767\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 37s 1ms/step - loss: 0.1701 - val_loss: 0.1636\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 40s 2ms/step - loss: 0.1615 - val_loss: 0.1581\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 39s 2ms/step - loss: 0.1577 - val_loss: 0.1555\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.1557 - val_loss: 0.1539\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 41s 2ms/step - loss: 0.1544 - val_loss: 0.1527\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 42s 2ms/step - loss: 0.1534 - val_loss: 0.1518\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 41s 2ms/step - loss: 0.1525 - val_loss: 0.1510\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 44s 2ms/step - loss: 0.1518 - val_loss: 0.1503\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 43s 2ms/step - loss: 0.1511 - val_loss: 0.1496\n",
      "12411/12411 [==============================] - 15s 1ms/step - loss: 0.1505\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 44s 2ms/step - loss: 0.1981 - val_loss: 0.1784\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 43s 2ms/step - loss: 0.1712 - val_loss: 0.1646\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 38s 2ms/step - loss: 0.1621 - val_loss: 0.1587\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 37s 2ms/step - loss: 0.1581 - val_loss: 0.1559\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.1559 - val_loss: 0.1541\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 40s 2ms/step - loss: 0.1545 - val_loss: 0.1529\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 34s 1ms/step - loss: 0.1534 - val_loss: 0.1519\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 38s 2ms/step - loss: 0.1525 - val_loss: 0.1511\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 37s 1ms/step - loss: 0.1518 - val_loss: 0.1504\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.1511 - val_loss: 0.1497\n",
      "12411/12411 [==============================] - 13s 1ms/step - loss: 0.1508\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 46s 2ms/step - loss: 0.2216 - val_loss: 0.1969\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 48s 2ms/step - loss: 0.1833 - val_loss: 0.1714\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 44s 2ms/step - loss: 0.1639 - val_loss: 0.1573\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 51s 2ms/step - loss: 0.1557 - val_loss: 0.1531\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 44s 2ms/step - loss: 0.1531 - val_loss: 0.1513\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 49s 2ms/step - loss: 0.1517 - val_loss: 0.1501\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 47s 2ms/step - loss: 0.1507 - val_loss: 0.1492\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 54s 2ms/step - loss: 0.1498 - val_loss: 0.1484\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 57s 2ms/step - loss: 0.1491 - val_loss: 0.1477\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 49s 2ms/step - loss: 0.1485 - val_loss: 0.1472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12411/12411 [==============================] - 15s 1ms/step - loss: 0.1485\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 44s 2ms/step - loss: 0.2232 - val_loss: 0.1989\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 47s 2ms/step - loss: 0.1851 - val_loss: 0.1740\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 41s 2ms/step - loss: 0.1669 - val_loss: 0.1595\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 46s 2ms/step - loss: 0.1568 - val_loss: 0.1532\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 43s 2ms/step - loss: 0.1531 - val_loss: 0.1509\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 47s 2ms/step - loss: 0.1514 - val_loss: 0.1497\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 44s 2ms/step - loss: 0.1504 - val_loss: 0.1487\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1495 - val_loss: 0.1479\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 46s 2ms/step - loss: 0.1488 - val_loss: 0.1473\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 51s 2ms/step - loss: 0.1482 - val_loss: 0.1467\n",
      "12411/12411 [==============================] - 13s 1ms/step - loss: 0.1476\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 46s 2ms/step - loss: 0.2204 - val_loss: 0.1946\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 50s 2ms/step - loss: 0.1788 - val_loss: 0.1659\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 47s 2ms/step - loss: 0.1610 - val_loss: 0.1565\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 50s 2ms/step - loss: 0.1558 - val_loss: 0.1535\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 47s 2ms/step - loss: 0.1537 - val_loss: 0.1519\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 50s 2ms/step - loss: 0.1522 - val_loss: 0.1505\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 47s 2ms/step - loss: 0.1510 - val_loss: 0.1494\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 50s 2ms/step - loss: 0.1500 - val_loss: 0.1485\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 47s 2ms/step - loss: 0.1491 - val_loss: 0.1477\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 50s 2ms/step - loss: 0.1484 - val_loss: 0.1469\n",
      "12411/12411 [==============================] - 13s 1ms/step - loss: 0.1480\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 40s 2ms/step - loss: 0.1829 - val_loss: 0.1602\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 38s 2ms/step - loss: 0.1560 - val_loss: 0.1523\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.1518 - val_loss: 0.1496\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 42s 2ms/step - loss: 0.1496 - val_loss: 0.1478\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.1481 - val_loss: 0.1465\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 39s 2ms/step - loss: 0.1470 - val_loss: 0.1456\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 39s 2ms/step - loss: 0.1463 - val_loss: 0.1450\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 37s 2ms/step - loss: 0.1457 - val_loss: 0.1445\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 42s 2ms/step - loss: 0.1453 - val_loss: 0.1441\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.1450 - val_loss: 0.1439\n",
      "12411/12411 [==============================] - 12s 1ms/step - loss: 0.1452\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 40s 2ms/step - loss: 0.1811 - val_loss: 0.1584\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 38s 2ms/step - loss: 0.1552 - val_loss: 0.1517\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 42s 2ms/step - loss: 0.1515 - val_loss: 0.1492\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.1495 - val_loss: 0.1475\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 42s 2ms/step - loss: 0.1481 - val_loss: 0.1464\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.1471 - val_loss: 0.1455\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 43s 2ms/step - loss: 0.1464 - val_loss: 0.1449\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 37s 1ms/step - loss: 0.1459 - val_loss: 0.1444\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 43s 2ms/step - loss: 0.1455 - val_loss: 0.1442\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 36s 1ms/step - loss: 0.1451 - val_loss: 0.1439\n",
      "12411/12411 [==============================] - 11s 872us/step - loss: 0.1448\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 41s 2ms/step - loss: 0.1838 - val_loss: 0.1612\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 35s 1ms/step - loss: 0.1568 - val_loss: 0.1527\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 40s 2ms/step - loss: 0.1521 - val_loss: 0.1497\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 37s 1ms/step - loss: 0.1498 - val_loss: 0.1478\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 39s 2ms/step - loss: 0.1483 - val_loss: 0.1466\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 39s 2ms/step - loss: 0.1472 - val_loss: 0.1457\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 42s 2ms/step - loss: 0.1465 - val_loss: 0.1450\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 44s 2ms/step - loss: 0.1459 - val_loss: 0.1445\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 38s 2ms/step - loss: 0.1454 - val_loss: 0.1441\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 42s 2ms/step - loss: 0.1451 - val_loss: 0.1439\n",
      "12411/12411 [==============================] - 12s 945us/step - loss: 0.1449\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 54s 2ms/step - loss: 0.2199 - val_loss: 0.1948\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 43s 2ms/step - loss: 0.1821 - val_loss: 0.1710\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 49s 2ms/step - loss: 0.1647 - val_loss: 0.1591\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 43s 2ms/step - loss: 0.1575 - val_loss: 0.1549\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 48s 2ms/step - loss: 0.1547 - val_loss: 0.1528\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 44s 2ms/step - loss: 0.1530 - val_loss: 0.1514\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 50s 2ms/step - loss: 0.1517 - val_loss: 0.1502\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 49s 2ms/step - loss: 0.1506 - val_loss: 0.1491\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 47s 2ms/step - loss: 0.1496 - val_loss: 0.1482\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 51s 2ms/step - loss: 0.1488 - val_loss: 0.1474\n",
      "12411/12411 [==============================] - 13s 1ms/step - loss: 0.1487\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 45s 2ms/step - loss: 0.2198 - val_loss: 0.1945\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 53s 2ms/step - loss: 0.1819 - val_loss: 0.1706\n",
      "Epoch 3/10\n",
      "24821/24821 [==============================] - 56s 2ms/step - loss: 0.1641 - val_loss: 0.1580\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1565 - val_loss: 0.1536\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 54s 2ms/step - loss: 0.1536 - val_loss: 0.1515\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 44s 2ms/step - loss: 0.1519 - val_loss: 0.1500\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 51s 2ms/step - loss: 0.1506 - val_loss: 0.1489\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 45s 2ms/step - loss: 0.1496 - val_loss: 0.1480\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 50s 2ms/step - loss: 0.1488 - val_loss: 0.1472\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 45s 2ms/step - loss: 0.1481 - val_loss: 0.1466\n",
      "12411/12411 [==============================] - 13s 1ms/step - loss: 0.1476\n",
      "Epoch 1/10\n",
      "24821/24821 [==============================] - 49s 2ms/step - loss: 0.2229 - val_loss: 0.1934\n",
      "Epoch 2/10\n",
      "24821/24821 [==============================] - 45s 2ms/step - loss: 0.1748 - val_loss: 0.1614\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24821/24821 [==============================] - 48s 2ms/step - loss: 0.1573 - val_loss: 0.1534\n",
      "Epoch 4/10\n",
      "24821/24821 [==============================] - 52s 2ms/step - loss: 0.1531 - val_loss: 0.1511\n",
      "Epoch 5/10\n",
      "24821/24821 [==============================] - 51s 2ms/step - loss: 0.1514 - val_loss: 0.1498\n",
      "Epoch 6/10\n",
      "24821/24821 [==============================] - 54s 2ms/step - loss: 0.1503 - val_loss: 0.1487\n",
      "Epoch 7/10\n",
      "24821/24821 [==============================] - 51s 2ms/step - loss: 0.1494 - val_loss: 0.1479\n",
      "Epoch 8/10\n",
      "24821/24821 [==============================] - 56s 2ms/step - loss: 0.1486 - val_loss: 0.1472\n",
      "Epoch 9/10\n",
      "24821/24821 [==============================] - 50s 2ms/step - loss: 0.1479 - val_loss: 0.1465\n",
      "Epoch 10/10\n",
      "24821/24821 [==============================] - 55s 2ms/step - loss: 0.1473 - val_loss: 0.1459\n",
      "12411/12411 [==============================] - 13s 1ms/step - loss: 0.1470\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fa168249310>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-80e1dfa580e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# we clone again after setting params in case some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[1;32m    762\u001b[0m                 **self.best_params_))\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fa168249310>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "rnd_search_cv.fit(X_train_tr,y_train,epochs=10,validation_data=(X_val_tr,y_val),callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01304080507013371, 'n_hidden': 3, 'n_neurons': 475}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.15756651759147644"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d28ab2d49804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "model =rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #Learning Curves\n",
    "pd.DataFrame(prefit.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "# plt.savefig('../plots/learning_Curves.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-01 15:50:23.340087: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-10-01 15:50:23.481626: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1800000000 Hz\n",
      "2020-10-01 15:50:23.492361: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fffdd333bf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-01 15:50:23.492915: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-10-01 15:50:23.501819: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "#DNN model\n",
    "def build_model(n_hidden=1,n_neurons=30,learning_rate=3e-3,input_shapes=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shapes))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons,activation='relu',kernel_initializer=\"he_normal\"))\n",
    "    he_avg_init = keras.initializers.VarianceScaling(scale=2.,mode='fan_avg',distribution='uniform')\n",
    "    model.add(keras.layers.Dense(2,activation='sigmoid',kernel_initializer=he_avg_init))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=optimizer,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "l_rate =  0.01304080507013371\n",
    "\n",
    "#Tuned Model\n",
    "model = build_model(n_hidden=3,n_neurons=475,learning_rate=l_rate,input_shapes=len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37231/37231 [==============================] - 191s 5ms/step - loss: 0.4236 - accuracy: 0.8075 - val_loss: 0.4088 - val_accuracy: 0.8171\n"
     ]
    }
   ],
   "source": [
    "prefit = model.fit(X_train_tr,y_train,epochs=1,validation_data=(X_val_tr,y_val),callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7063225 , 0.19619861],\n",
       "       [0.5586795 , 0.05687663],\n",
       "       [0.43129814, 0.12285158],\n",
       "       ...,\n",
       "       [0.49909323, 0.19855192],\n",
       "       [0.4417659 , 0.0430665 ],\n",
       "       [0.5519167 , 0.0350956 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out = np.array(y_test,dtype='float32')\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1270503    0\n",
       "869728     0\n",
       "839203     0\n",
       "606202     1\n",
       "314340     1\n",
       "          ..\n",
       "118704     1\n",
       "901315     0\n",
       "724600     0\n",
       "946506     0\n",
       "861798     0\n",
       "Name: target, Length: 134957, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(figsize=(6,5))\n",
    "plt.grid(True)\n",
    "fpr,tpr,th = roc_curve(y_true=y_out,y_score=y_pred[:,1])\n",
    "auc = roc_auc_score(y_out,y_pred[:,1])\n",
    "plt.plot(tpr,1-fpr)\n",
    "plt.text(0.15,0.35,f'auc value: {auc}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = ROOT.TCanvas()\n",
    "gr = ROOT.TGraph(fpr.size,tpr,1-fpr)\n",
    "gr.Draw(\"C\")\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48552"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'DNN response with JSS')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Bins =10\n",
    "plt.plot(figsize=(6,5))\n",
    "plt.hist(y_pred[:,0],bins=Bins,range=(0.01,0.99),density=True,alpha=0.7,label='qq')\n",
    "plt.hist(y_pred[:,1],bins=Bins,range=(0.01,0.99),density=True,alpha=0.7,label='SMbkg')\n",
    "plt.legend(loc='upper center')\n",
    "plt.ylim(0,3)\n",
    "plt.xlabel('DNN response with JSS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_inv = np.array(testdataset['invmass'],dtype=[('m_inv',np.float32)])\n",
    "sig_score = y_pred[:,1].astype([('sig_score',np.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from root_numpy import array2root,array2tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_root = ROOT.TFile('test.root',\"update\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1053"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = array2tree(m_inv,'tree')\n",
    "array2tree(sig_score,'tree')\n",
    "test_root.Write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TTree::SetEntries>: Tree branches have different numbers of entries, eg sig_score has 134957 entries while m_inv has 269914 entries.\n"
     ]
    }
   ],
   "source": [
    "array2root(m_inv,'test_.root',treename='tree',mode='update')\n",
    "array2root(sig_score,'test_.root',treename='tree',mode='update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = ROOT.TFile('test.root','update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = array2root(m_inv,'test_.root',treename='tree',mode='update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_df = testdataset.loc[testdataset['target']=='0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptJ1</th>\n",
       "      <th>ptJ2</th>\n",
       "      <th>invmass</th>\n",
       "      <th>DRJ1J2</th>\n",
       "      <th>etaJ1</th>\n",
       "      <th>etaJ2</th>\n",
       "      <th>pTDJ1</th>\n",
       "      <th>pTDJ2</th>\n",
       "      <th>LHAJ1</th>\n",
       "      <th>LHAJ2</th>\n",
       "      <th>...</th>\n",
       "      <th>s2J2</th>\n",
       "      <th>pmJ1</th>\n",
       "      <th>pmJ2</th>\n",
       "      <th>tmJ1</th>\n",
       "      <th>tmJ2</th>\n",
       "      <th>widthJ1</th>\n",
       "      <th>widthJ2</th>\n",
       "      <th>girthJ1</th>\n",
       "      <th>girthJ2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1270503</th>\n",
       "      <td>920.556030</td>\n",
       "      <td>694.270020</td>\n",
       "      <td>1728.776733</td>\n",
       "      <td>3.19922</td>\n",
       "      <td>-1.450070</td>\n",
       "      <td>-0.647956</td>\n",
       "      <td>0.407418</td>\n",
       "      <td>0.442950</td>\n",
       "      <td>0.249925</td>\n",
       "      <td>0.158206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.078307</td>\n",
       "      <td>0.029794</td>\n",
       "      <td>0.011820</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869728</th>\n",
       "      <td>977.276978</td>\n",
       "      <td>849.578003</td>\n",
       "      <td>1815.327881</td>\n",
       "      <td>2.95761</td>\n",
       "      <td>0.204744</td>\n",
       "      <td>0.154638</td>\n",
       "      <td>0.308062</td>\n",
       "      <td>0.271052</td>\n",
       "      <td>0.375982</td>\n",
       "      <td>0.387466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020248</td>\n",
       "      <td>49</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>0.191190</td>\n",
       "      <td>0.195617</td>\n",
       "      <td>0.087703</td>\n",
       "      <td>0.095123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839203</th>\n",
       "      <td>830.455017</td>\n",
       "      <td>740.653015</td>\n",
       "      <td>1714.205811</td>\n",
       "      <td>3.21874</td>\n",
       "      <td>-0.698874</td>\n",
       "      <td>-1.555030</td>\n",
       "      <td>0.229689</td>\n",
       "      <td>0.823940</td>\n",
       "      <td>0.379816</td>\n",
       "      <td>0.186277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>0.156358</td>\n",
       "      <td>0.052102</td>\n",
       "      <td>0.034489</td>\n",
       "      <td>0.012108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668350</th>\n",
       "      <td>723.604980</td>\n",
       "      <td>710.296997</td>\n",
       "      <td>1430.953857</td>\n",
       "      <td>2.28314</td>\n",
       "      <td>-0.380906</td>\n",
       "      <td>-1.362930</td>\n",
       "      <td>0.321829</td>\n",
       "      <td>0.717977</td>\n",
       "      <td>0.359688</td>\n",
       "      <td>0.222939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>0.158036</td>\n",
       "      <td>0.083569</td>\n",
       "      <td>0.064314</td>\n",
       "      <td>0.035901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281403</th>\n",
       "      <td>909.685974</td>\n",
       "      <td>754.362976</td>\n",
       "      <td>1710.412720</td>\n",
       "      <td>3.12107</td>\n",
       "      <td>0.262633</td>\n",
       "      <td>-0.248330</td>\n",
       "      <td>0.599768</td>\n",
       "      <td>0.409279</td>\n",
       "      <td>0.162300</td>\n",
       "      <td>0.322845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010831</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0.029551</td>\n",
       "      <td>0.119836</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.026503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722138</th>\n",
       "      <td>974.859985</td>\n",
       "      <td>873.965027</td>\n",
       "      <td>1857.237549</td>\n",
       "      <td>3.07251</td>\n",
       "      <td>-0.645853</td>\n",
       "      <td>-0.879272</td>\n",
       "      <td>0.271995</td>\n",
       "      <td>0.449791</td>\n",
       "      <td>0.228012</td>\n",
       "      <td>0.379112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>0.058282</td>\n",
       "      <td>0.176638</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.078418</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901315</th>\n",
       "      <td>880.844971</td>\n",
       "      <td>871.333984</td>\n",
       "      <td>2011.327026</td>\n",
       "      <td>3.30382</td>\n",
       "      <td>1.732070</td>\n",
       "      <td>0.657103</td>\n",
       "      <td>0.284619</td>\n",
       "      <td>0.269506</td>\n",
       "      <td>0.251780</td>\n",
       "      <td>0.437628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032669</td>\n",
       "      <td>54</td>\n",
       "      <td>63</td>\n",
       "      <td>27</td>\n",
       "      <td>46</td>\n",
       "      <td>0.086682</td>\n",
       "      <td>0.216576</td>\n",
       "      <td>0.024060</td>\n",
       "      <td>0.079883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724600</th>\n",
       "      <td>887.905029</td>\n",
       "      <td>884.276978</td>\n",
       "      <td>1810.455566</td>\n",
       "      <td>3.16580</td>\n",
       "      <td>0.165679</td>\n",
       "      <td>-0.249287</td>\n",
       "      <td>0.602745</td>\n",
       "      <td>0.264591</td>\n",
       "      <td>0.105069</td>\n",
       "      <td>0.425641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033674</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>0.212068</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946506</th>\n",
       "      <td>1436.229980</td>\n",
       "      <td>840.208984</td>\n",
       "      <td>2606.331543</td>\n",
       "      <td>3.32220</td>\n",
       "      <td>-0.746192</td>\n",
       "      <td>0.457095</td>\n",
       "      <td>0.413254</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.100063</td>\n",
       "      <td>0.213073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.016331</td>\n",
       "      <td>0.053105</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861798</th>\n",
       "      <td>1074.560059</td>\n",
       "      <td>832.442017</td>\n",
       "      <td>1934.294067</td>\n",
       "      <td>3.15723</td>\n",
       "      <td>-0.317565</td>\n",
       "      <td>-0.741961</td>\n",
       "      <td>0.489016</td>\n",
       "      <td>0.229690</td>\n",
       "      <td>0.309375</td>\n",
       "      <td>0.630818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080932</td>\n",
       "      <td>38</td>\n",
       "      <td>68</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>0.108813</td>\n",
       "      <td>0.413716</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>0.200983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70341 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ptJ1        ptJ2      invmass   DRJ1J2     etaJ1     etaJ2  \\\n",
       "1270503   920.556030  694.270020  1728.776733  3.19922 -1.450070 -0.647956   \n",
       "869728    977.276978  849.578003  1815.327881  2.95761  0.204744  0.154638   \n",
       "839203    830.455017  740.653015  1714.205811  3.21874 -0.698874 -1.555030   \n",
       "668350    723.604980  710.296997  1430.953857  2.28314 -0.380906 -1.362930   \n",
       "1281403   909.685974  754.362976  1710.412720  3.12107  0.262633 -0.248330   \n",
       "...              ...         ...          ...      ...       ...       ...   \n",
       "722138    974.859985  873.965027  1857.237549  3.07251 -0.645853 -0.879272   \n",
       "901315    880.844971  871.333984  2011.327026  3.30382  1.732070  0.657103   \n",
       "724600    887.905029  884.276978  1810.455566  3.16580  0.165679 -0.249287   \n",
       "946506   1436.229980  840.208984  2606.331543  3.32220 -0.746192  0.457095   \n",
       "861798   1074.560059  832.442017  1934.294067  3.15723 -0.317565 -0.741961   \n",
       "\n",
       "            pTDJ1     pTDJ2     LHAJ1     LHAJ2  ...      s2J2  pmJ1  pmJ2  \\\n",
       "1270503  0.407418  0.442950  0.249925  0.158206  ...  0.004815    23    13   \n",
       "869728   0.308062  0.271052  0.375982  0.387466  ...  0.020248    49    60   \n",
       "839203   0.229689  0.823940  0.379816  0.186277  ...  0.001960    51    28   \n",
       "668350   0.321829  0.717977  0.359688  0.222939  ...  0.005012    38    34   \n",
       "1281403  0.599768  0.409279  0.162300  0.322845  ...  0.010831    16    41   \n",
       "...           ...       ...       ...       ...  ...       ...   ...   ...   \n",
       "722138   0.271995  0.449791  0.228012  0.379112  ...  0.020106    27    36   \n",
       "901315   0.284619  0.269506  0.251780  0.437628  ...  0.032669    54    63   \n",
       "724600   0.602745  0.264591  0.105069  0.425641  ...  0.033674    11    60   \n",
       "946506   0.413254  0.703787  0.100063  0.213073  ...  0.002761    17    19   \n",
       "861798   0.489016  0.229690  0.309375  0.630818  ...  0.080932    38    68   \n",
       "\n",
       "         tmJ1 tmJ2   widthJ1   widthJ2   girthJ1   girthJ2  target  \n",
       "1270503     9    8  0.078307  0.029794  0.011820  0.001702       0  \n",
       "869728     26   32  0.191190  0.195617  0.087703  0.095123       0  \n",
       "839203     25   18  0.156358  0.052102  0.034489  0.012108       0  \n",
       "668350     24   19  0.158036  0.083569  0.064314  0.035901       0  \n",
       "1281403    12   21  0.029551  0.119836  0.001464  0.026503       0  \n",
       "...       ...  ...       ...       ...       ...       ...     ...  \n",
       "722138     16   24  0.058282  0.176638  0.005178  0.078418       0  \n",
       "901315     27   46  0.086682  0.216576  0.024060  0.079883       0  \n",
       "724600      9   26  0.014623  0.212068  0.000743  0.078100       0  \n",
       "946506     12   11  0.016331  0.053105  0.001726  0.006404       0  \n",
       "861798     18   36  0.108813  0.413716  0.022161  0.200983       0  \n",
       "\n",
       "[70341 rows x 23 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = np.array([1,2,3])\n",
    "l2 = np.array([4,5,6])\n",
    "l = zip(l1,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_= list(l)\n",
    "ar = np.array(l_,dtype=[('a','int32'),('b','int32')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1, 4), (2, 5), (3, 6)], dtype=[('a', '<i4'), ('b', '<i4')])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
